{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "audio_processing.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPn7Jm9UKKtoEHz8SEPHpNl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hsnam95/class2022Spring/blob/main/audio_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# \bAudio Processing\n",
        "---\n",
        "\n",
        "https://musiclab.chromeexperiments.com/Spectrogram/\n",
        "\n",
        "### Fourier transform (분석용)\n",
        "* spectrum은 주어진 signal에 대해 어떤 주파수 성분이 많이 있나?\n",
        "* spectrogram은 spectrum을 time 축으로 concatenate한 것\n",
        "* 방법: signal (inner product) a series of complex phasors with different frequencies\n",
        "* inner product는 일종의 correlation (즉, 해당 frequency가 얼마나 있는지 probing)\n",
        "* 왜? sine phasor 안 쓰나? phase sensitivity 때문\n",
        "\n",
        "### Filter (변환용)\n",
        "* A --> function -->  B\n",
        "* signal A --> filter --> signal B\n",
        "* 신호 (time function)를 입력으로 하는 함수를 filter라고 함\n",
        "* 왜? filter 라고 부름? 이 함수의 목적이 특정 주파수에 대한 manipulation이므로.\n",
        "(예: 어떤 주파수대를 작게, 크게, 통과, 제거 등)\n",
        "* 방법: weighted sum of signal's shifts (두가지 방법: FIR, IIR)\n",
        "\n",
        "  * FIR: Y(k) = b<sub>1</sub>X(k) + b<sub>2</sub>X(k-1) + ... \n",
        "    - Y = H * X\n",
        "  * IIR: a<sub>1</sub>Y(k) + a<sub>2</sub>Y(k-1) + ... = X(k)\n",
        "    - Y = (1/H) * X\n",
        "\n",
        "### Auto correlation\n",
        "* measuring pitch / F0\n",
        "\n",
        "### RMS: root mean square\n",
        "* measuring intensity"
      ],
      "metadata": {
        "id": "1gsMMEn32yiZ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WAs2J9dWcUv"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display as ipd\n",
        "import librosa, librosa.display"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### load / plot / play sound file"
      ],
      "metadata": {
        "id": "VyICGWoRAUuV"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QqXtTXxn9B7"
      },
      "source": [
        "# from google.colab import files\n",
        "# fn = files.upload()\n",
        "import os\n",
        "url = \"https://raw.githubusercontent.com/hsnam95/class2022Spring/main/aeiou.wav\"\n",
        "os.system(\"curl \" + url + \" > aeiou.wav\")\n",
        "\n",
        "s, sr = librosa.load('aeiou.wav')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = librosa.util.normalize(s)\n",
        "librosa.display.waveplot(s, sr)\n",
        "ipd.Audio(s[7000:12000], rate=sr)"
      ],
      "metadata": {
        "id": "GYJxi9xvVvt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fourier Transform for Spectrogram"
      ],
      "metadata": {
        "id": "0OSaiS-7AwZr"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NcZn-caoYSt"
      },
      "source": [
        "s_preemp = librosa.effects.preemphasis(s)\n",
        "\n",
        "n_fft=512\n",
        "hop_length=int(0.001*sr)\n",
        "win_length=int(sr*0.008)\n",
        "\n",
        "spec = librosa.stft(s_preemp, n_fft=n_fft, hop_length=hop_length, win_length=win_length, window = 'hann')\n",
        "magspec = np.abs(spec)\n",
        "dBspec = librosa.amplitude_to_db(magspec, ref=np.max)\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "librosa.display.specshow(dBspec, sr=sr, x_coords = np.linspace(1, len(s), dBspec.shape[1])/sr , x_axis='time', y_axis='linear', cmap='Greys')\n",
        "plt.ylim((0,5000))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filter for audio transformation"
      ],
      "metadata": {
        "id": "VZQs9tMxCPad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.signal import lfilter\n",
        "sig = s[7000:12000]\n",
        "sig = lfilter(np.array([1]), np.array([1]), sig, axis=0)\n",
        "librosa.display.waveplot(sig, sr)\n",
        "ipd.Audio(sig, rate=sr)"
      ],
      "metadata": {
        "id": "xlTto7H_RA-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RMS(Root Mean Square) for intensity"
      ],
      "metadata": {
        "id": "N9NfP2cPCw7P"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkJTYAixfNhK"
      },
      "source": [
        "rms = librosa.feature.rms(s)\n",
        "plt.plot(rms[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Autocorrelation for pitch(F0) measurement"
      ],
      "metadata": {
        "id": "O9mNH08CDAR-"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoOGXdFBgpx1"
      },
      "source": [
        "F0, voiced_flag, voiced_prob = librosa.pyin(s, 60, 200)\n",
        "plt.plot(F0, '.')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}